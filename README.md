# Language-Technology
NLP TEXT SUMMARIZATION WITH DEEP LEARNING, KYRIAKOPOULOU EVANGELIA, DMCI

Files: 
Text_Summarization_With_Transformers.ipynb: Colab Notebook of Transformers for text summarization
Text_Summarization_With_Transformers.pdf: Report of experimentation and alternative methods for text summarization

Requirements : Check requirements.txt file 

Directories:

- Chapter13: Repository from "Deep Learning for NLP and Speech Recognition" github, with processed files (Deprecated)
 Link: https://github.com/SpringerNLP/Chapter13?fbclid=IwAR0lj12MtnQLtWUjghpSKf852C0jUkiz3QMYrUU3U33NyNdsdg2UruKa48A

The codes from the Springer Book/Chapter13 are deprecated, so we used Transformers method for Text Summarization.
For our successful training (Transformer) we uploaded the model on the Hugging Face Model Hub.

You can find it here: 

Link: https://huggingface.co/Evangeliaa/t5-small-finetuned-xsum (1 epoch fine-tuning)

Link: https://huggingface.co/Evangeliaa/t5-small-finetuned-xsum_3epoch_batch8 (3 epoch and hyper-parameter tuning)

For t5-small pre-trained model
Link Here: https://huggingface.co/t5-small?fbclid=IwAR1BNN-p4Eb0sNM45b0KhlPWtrIq11Blpnis6cuni7yealYXVRnAPAxjckU

For Xsum Dataset
Link Here: https://huggingface.co/datasets/xsum?fbclid=IwAR3mGpVc4tt0YgwScfyg4jEa9KDiTzpk3ax4vUt66FfB343RJCIjqieKZzg

Documentation for the code: 
https://www.thepythoncode.com/article/text-summarization-using-huggingface-transformers-python
https://keras.io/examples/nlp/t5_hf_summarization/?fbclid=IwAR2UNjExKJGZ8-zLQ2WUEFfCc0PWcW4NizHsMjZ9Ol-7C21xvEtRvYB30Wk

